{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/transformer_tutorial.ipynb","timestamp":1726541081980}]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9535015,"sourceType":"datasetVersion","datasetId":5807407}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\nSequence-to-Sequence Modeling with nn.Transformer and TorchText\n===============================================================\n\n![](https://github.com/pytorch/tutorials/blob/gh-pages/_static/img/transformer_architecture.jpg?raw=1)\n\n\n\n","metadata":{"id":"FOcv8kNtIuqQ"}},{"cell_type":"code","source":"!pip uninstall -y torch torchtext\n!pip install torch==2.0.0 torchtext==0.15.1","metadata":{"id":"6RW7qlwyJVzn","executionInfo":{"status":"ok","timestamp":1726534601124,"user_tz":300,"elapsed":127976,"user":{"displayName":"","userId":""}},"outputId":"bb80f457-a3ac-4983-dd10-c582b0972ae0","colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2024-10-03T13:15:42.008125Z","iopub.execute_input":"2024-10-03T13:15:42.008545Z","iopub.status.idle":"2024-10-03T13:17:53.181556Z","shell.execute_reply.started":"2024-10-03T13:15:42.008500Z","shell.execute_reply":"2024-10-03T13:17:53.180177Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\n\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting torch==2.0.0\n  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nCollecting torchtext==0.15.1\n  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1.4)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch==2.0.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.1) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.1) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.1) (1.26.4)\nCollecting torchdata==0.6.0 (from torchtext==0.15.1)\n  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (919 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (70.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.43.0)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.6.0->torchtext==0.15.1) (1.26.18)\nCollecting cmake (from triton==2.0.0->torch==2.0.0)\n  Downloading cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.0)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.1) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.1) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\nDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.30.4 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1 triton-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.optim as optim\nimport time\n\nimport os\nimport math\n\n# Defina o comprimento máximo das sequências\nMAX_LENGTH = 100\n\n# Defina o tokenizador\ntokenizer = get_tokenizer('basic_english')","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:17:53.186116Z","iopub.execute_input":"2024-10-03T13:17:53.186606Z","iopub.status.idle":"2024-10-03T13:17:56.235234Z","shell.execute_reply.started":"2024-10-03T13:17:53.186568Z","shell.execute_reply":"2024-10-03T13:17:56.234443Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Verificar se a GPU está disponível\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Exibir a informação\nif device.type == 'cuda':\n    print(\"Rodando na GPU:\", torch.cuda.get_device_name(0))\nelse:\n    print(\"Rodando na CPU\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:17:56.236228Z","iopub.execute_input":"2024-10-03T13:17:56.236679Z","iopub.status.idle":"2024-10-03T13:17:56.293321Z","shell.execute_reply.started":"2024-10-03T13:17:56.236646Z","shell.execute_reply":"2024-10-03T13:17:56.292366Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Rodando na GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Função para ler os dados de texto\ndef load_wikitext(filepath):\n    with open(filepath, 'r', encoding='utf-8') as f:\n        return f.read().splitlines()","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:03.201932Z","iopub.execute_input":"2024-10-03T13:18:03.203594Z","iopub.status.idle":"2024-10-03T13:18:03.210347Z","shell.execute_reply.started":"2024-10-03T13:18:03.203549Z","shell.execute_reply":"2024-10-03T13:18:03.209046Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Caminhos para os arquivos no Google Drive\nfolder = '/kaggle/input/wikitext-2'\ntrain_file = os.path.join(folder, 'wiki.train.tokens')\nval_file = os.path.join(folder, 'wiki.valid.tokens')\ntest_file = os.path.join(folder, 'wiki.test.tokens')","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:04.482245Z","iopub.execute_input":"2024-10-03T13:18:04.482631Z","iopub.status.idle":"2024-10-03T13:18:04.487787Z","shell.execute_reply.started":"2024-10-03T13:18:04.482597Z","shell.execute_reply":"2024-10-03T13:18:04.486691Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Carregar os dados\ntrain_txt = load_wikitext(train_file)\nval_txt = load_wikitext(val_file)\ntest_txt = load_wikitext(test_file)","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:04.865452Z","iopub.execute_input":"2024-10-03T13:18:04.866347Z","iopub.status.idle":"2024-10-03T13:18:05.104428Z","shell.execute_reply.started":"2024-10-03T13:18:04.866282Z","shell.execute_reply":"2024-10-03T13:18:05.103431Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Função para truncar ou preencher tokens\ndef truncate_or_pad(tokens, max_length):\n    if len(tokens) > max_length:\n        return tokens[:max_length]\n    else:\n        return tokens + ['<pad>'] * (max_length - len(tokens))","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:05.106054Z","iopub.execute_input":"2024-10-03T13:18:05.106385Z","iopub.status.idle":"2024-10-03T13:18:05.111527Z","shell.execute_reply.started":"2024-10-03T13:18:05.106350Z","shell.execute_reply":"2024-10-03T13:18:05.110480Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Tokenizar e ajustar as sequências\ntrain_tokens = [truncate_or_pad(tokenizer(line), MAX_LENGTH) for line in train_txt]\nval_tokens = [truncate_or_pad(tokenizer(line), MAX_LENGTH) for line in val_txt]\ntest_tokens = [truncate_or_pad(tokenizer(line), MAX_LENGTH) for line in test_txt]","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:05.262761Z","iopub.execute_input":"2024-10-03T13:18:05.263108Z","iopub.status.idle":"2024-10-03T13:18:07.329120Z","shell.execute_reply.started":"2024-10-03T13:18:05.263063Z","shell.execute_reply":"2024-10-03T13:18:07.328335Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Defina os tokens especiais\nspecials = ['<unk>', '<sos>', '<eos>', '<pad>']","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:07.330924Z","iopub.execute_input":"2024-10-03T13:18:07.331561Z","iopub.status.idle":"2024-10-03T13:18:07.336282Z","shell.execute_reply.started":"2024-10-03T13:18:07.331513Z","shell.execute_reply":"2024-10-03T13:18:07.335215Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Função para construir o vocabulário com tokens especiais\ndef build_vocab_with_specials(tokens_list, specials):\n    # Adicione tokens especiais ao vocabulário\n    vocab = build_vocab_from_iterator(tokens_list, specials=specials, min_freq=1)\n    vocab.set_default_index(vocab[\"<unk>\"])\n    return vocab","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:07.337630Z","iopub.execute_input":"2024-10-03T13:18:07.338483Z","iopub.status.idle":"2024-10-03T13:18:07.359491Z","shell.execute_reply.started":"2024-10-03T13:18:07.338437Z","shell.execute_reply":"2024-10-03T13:18:07.358555Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Criar o vocabulário com tokens especiais\nvocab = build_vocab_with_specials(train_tokens, specials)","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:07.362078Z","iopub.execute_input":"2024-10-03T13:18:07.362424Z","iopub.status.idle":"2024-10-03T13:18:07.863104Z","shell.execute_reply.started":"2024-10-03T13:18:07.362378Z","shell.execute_reply":"2024-10-03T13:18:07.862307Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Função para converter tokens em índices usando o vocabulário\ndef tokenize_and_numericalize(data, vocab):\n    # Converta tokens em índices inteiros e garanta que o tensor seja do tipo Long\n    return [torch.tensor([vocab[token] for token in tokenizer(line)], dtype=torch.long) for line in data]","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:07.864208Z","iopub.execute_input":"2024-10-03T13:18:07.864530Z","iopub.status.idle":"2024-10-03T13:18:07.869798Z","shell.execute_reply.started":"2024-10-03T13:18:07.864497Z","shell.execute_reply":"2024-10-03T13:18:07.868875Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Numeralizar os dados de treino, validação e teste\ntrain_data = tokenize_and_numericalize(train_txt, vocab)\nval_data = tokenize_and_numericalize(val_txt, vocab)\ntest_data = tokenize_and_numericalize(test_txt, vocab)","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:07.871204Z","iopub.execute_input":"2024-10-03T13:18:07.871974Z","iopub.status.idle":"2024-10-03T13:18:12.657639Z","shell.execute_reply.started":"2024-10-03T13:18:07.871931Z","shell.execute_reply":"2024-10-03T13:18:12.656528Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Definir parâmetros do modelo\nntokens = len(vocab)  # O tamanho do vocabulário\nemsize = 200          # Dimensão do embedding\nnhid = 200            # Dimensão do feedforward network model\nnlayers = 2           # Número de camadas do TransformerEncoder\nnhead = 2             # Número de cabeças na multiheadattention\ndropout = 0.2         # Valor de dropout\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:12.659183Z","iopub.execute_input":"2024-10-03T13:18:12.659584Z","iopub.status.idle":"2024-10-03T13:18:12.666627Z","shell.execute_reply.started":"2024-10-03T13:18:12.659540Z","shell.execute_reply":"2024-10-03T13:18:12.665641Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Definir modelo Transformer\nclass TransformerModel(nn.Module):\n    def __init__(self, ntokens, emsize, nhead, nhid, nlayers, dropout=0.2):\n        super(TransformerModel, self).__init__()\n        self.model_type = 'Transformer'\n        self.encoder = nn.Embedding(ntokens, emsize)\n        self.pos_encoder = nn.Sequential(\n            nn.Dropout(dropout)\n        )\n        encoder_layers = nn.TransformerEncoderLayer(emsize, nhead, nhid, dropout)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n        self.decoder = nn.Linear(emsize, ntokens)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.1\n        self.encoder.weight.data.uniform_(-initrange, initrange)\n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self, src):\n        src = self.encoder(src) * math.sqrt(emsize)\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src)\n        output = self.decoder(output)\n        return output","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:12.667986Z","iopub.execute_input":"2024-10-03T13:18:12.668364Z","iopub.status.idle":"2024-10-03T13:18:14.366965Z","shell.execute_reply.started":"2024-10-03T13:18:12.668320Z","shell.execute_reply":"2024-10-03T13:18:14.364804Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Inicializar o modelo\nmodel = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:14.368495Z","iopub.execute_input":"2024-10-03T13:18:14.368898Z","iopub.status.idle":"2024-10-03T13:18:15.417351Z","shell.execute_reply.started":"2024-10-03T13:18:14.368851Z","shell.execute_reply":"2024-10-03T13:18:15.416429Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Função para dividir os dados em batches\ndef batchify(data, bsz):\n    # Converte tokens em tensores e preenche com zeros\n    data = pad_sequence([item for item in data], batch_first=True)\n    nbatch = data.size(0) // bsz\n    data = data[:nbatch * bsz].view(bsz, -1).t().contiguous()\n    return data.to(device, dtype=torch.long)\n\nbatch_size = 20\ntrain_data = batchify(train_data, batch_size)\nval_data = batchify(val_data, batch_size)\ntest_data = batchify(test_data, batch_size)\n\ndef get_batch(source, i, bptt):\n    seq_len = min(bptt, len(source) - i - 1)\n    data = source[i:i + seq_len]\n    target = source[i + 1:i + 1 + seq_len]\n\n    if len(data) < bptt:\n        padding_len = bptt - len(data)\n        data = torch.cat([data, torch.full((padding_len, data.size(1)), vocab['<pad>'], dtype=torch.long)], dim=0)\n    if len(target) < bptt:\n        padding_len = bptt - len(target)\n        # Correctly pad the target tensor along dimension 0\n        target = torch.cat([target, torch.full((padding_len,), vocab['<pad>'], dtype=torch.long).unsqueeze(0).repeat(target.size(1), 1).t()], dim=0)\n    return data, target","metadata":{"id":"MJW_B4S3pXOL","executionInfo":{"status":"ok","timestamp":1726537995383,"user_tz":300,"elapsed":10277,"user":{"displayName":"","userId":""}},"outputId":"2879851d-0f80-44c0-d414-6101a5ce2ce1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-10-03T13:18:15.422573Z","iopub.execute_input":"2024-10-03T13:18:15.422864Z","iopub.status.idle":"2024-10-03T13:18:16.029527Z","shell.execute_reply.started":"2024-10-03T13:18:15.422833Z","shell.execute_reply":"2024-10-03T13:18:16.028623Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Ajuste a função get_batch para garantir que os tensores estejam no mesmo dispositivo\ndef get_batch(source, i, bptt, device):\n    data = source[i:i + bptt]\n    target = source[i + 1:i + 1 + bptt]  # O alvo é deslocado em uma posição\n    \n    # Se a sequência de dados for menor que o bptt, adicione padding\n    if len(data) < bptt:\n        padding_len = bptt - len(data)\n        # Criar o padding e mover para o mesmo dispositivo do 'data'\n        padding = torch.full((padding_len, data.size(1)), vocab['<pad>'], dtype=torch.long).to(device)\n        data = torch.cat([data, padding], dim=0)\n\n    if len(target) < bptt:\n        padding_len = bptt - len(target)\n        # Criar o padding e mover para o mesmo dispositivo do 'target'\n        padding = torch.full((padding_len, target.size(1)), vocab['<pad>'], dtype=torch.long).to(device)\n        target = torch.cat([target, padding], dim=0)\n    \n    return data.to(device), target.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:23:41.501902Z","iopub.execute_input":"2024-10-03T13:23:41.502342Z","iopub.status.idle":"2024-10-03T13:23:41.739360Z","shell.execute_reply.started":"2024-10-03T13:23:41.502303Z","shell.execute_reply":"2024-10-03T13:23:41.738401Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Configurações de treinamento\nbptt = 35  # Exemplo de comprimento do batch de sequência\ncriterion = nn.CrossEntropyLoss()\n\n# Definir o dispositivo (GPU ou CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Pegue uma amostra para checar\nsrc = train_data[:batch_size]\ndata, target = get_batch(src, 0, bptt, device)  # Exemplo de dados e alvos\n\n# Chamar a função com o dispositivo correto\ncheck_and_adjust_batch(data, target, model, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:23:41.501902Z","iopub.execute_input":"2024-10-03T13:23:41.502342Z","iopub.status.idle":"2024-10-03T13:23:41.739360Z","shell.execute_reply.started":"2024-10-03T13:23:41.502303Z","shell.execute_reply":"2024-10-03T13:23:41.738401Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Data shape: torch.Size([35, 20])\nTarget shape: torch.Size([35, 20])\nModel output shape: torch.Size([35, 20, 28378])\nAdjusted output shape: torch.Size([700, 28378])\nAdjusted target shape: torch.Size([700])\nLoss: 10.11091423034668\n","output_type":"stream"}]},{"cell_type":"code","source":"# Inicializar o modelo\nmodel = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:23:50.010722Z","iopub.execute_input":"2024-10-03T13:23:50.011097Z","iopub.status.idle":"2024-10-03T13:23:50.226946Z","shell.execute_reply.started":"2024-10-03T13:23:50.011065Z","shell.execute_reply":"2024-10-03T13:23:50.226066Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Função de treinamento\ndef train():\n    model.train()  # Ativar o modo de treinamento\n    total_loss = 0.\n    start_time = time.time()\n    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n        data, targets = get_batch(train_data, i, bptt,device)\n        optimizer.zero_grad()\n        output = model(data)\n        output_flat = output.view(-1, ntokens)\n        loss = criterion(output_flat, targets.view(-1))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        total_loss += loss.item()\n        if batch % log_interval == 0 and batch > 0:\n            cur_loss = total_loss / log_interval\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n                  'lr {:.5f} | loss {:5.2f} | ppl {:8.2f}'.format(\n                epoch, batch, len(train_data) // bptt,\n                lr, cur_loss, math.exp(cur_loss)))\n            total_loss = 0.\n            start_time = time.time()  # Reiniciar o tempo","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:23.642584Z","iopub.execute_input":"2024-10-03T13:27:23.642977Z","iopub.status.idle":"2024-10-03T13:27:23.651568Z","shell.execute_reply.started":"2024-10-03T13:27:23.642941Z","shell.execute_reply":"2024-10-03T13:27:23.650587Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Função de avaliação\ndef evaluate(eval_model, data_source):\n    eval_model.eval()  # Ativar o modo de avaliação\n    total_loss = 0.\n    with torch.no_grad():\n        for i in range(0, data_source.size(0) - 1, bptt):\n            data, targets = get_batch(data_source, i, bptt,device)\n            output = eval_model(data)\n            output_flat = output.view(-1, ntokens)\n            total_loss += len(data) * criterion(output_flat, targets.view(-1)).item()\n    return total_loss / (len(data_source) - 1)","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:29.213938Z","iopub.execute_input":"2024-10-03T13:27:29.214327Z","iopub.status.idle":"2024-10-03T13:27:29.221068Z","shell.execute_reply.started":"2024-10-03T13:27:29.214277Z","shell.execute_reply":"2024-10-03T13:27:29.220130Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Configurações de treinamento\nn_epochs = 5\nlr = 5.0\nbatch_size = 20\nbptt = 35\nlog_interval = 200","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:31.200958Z","iopub.execute_input":"2024-10-03T13:27:31.201336Z","iopub.status.idle":"2024-10-03T13:27:31.206364Z","shell.execute_reply.started":"2024-10-03T13:27:31.201301Z","shell.execute_reply":"2024-10-03T13:27:31.205275Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Inicializar o otimizador\noptimizer = optim.SGD(model.parameters(), lr=lr)","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:32.979560Z","iopub.execute_input":"2024-10-03T13:27:32.981501Z","iopub.status.idle":"2024-10-03T13:27:32.988172Z","shell.execute_reply.started":"2024-10-03T13:27:32.981435Z","shell.execute_reply":"2024-10-03T13:27:32.986853Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Inicializar o scheduler (opcional)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:33.646207Z","iopub.execute_input":"2024-10-03T13:27:33.647099Z","iopub.status.idle":"2024-10-03T13:27:33.651811Z","shell.execute_reply.started":"2024-10-03T13:27:33.647055Z","shell.execute_reply":"2024-10-03T13:27:33.650719Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Treinamento e avaliação\nstart_time = time.time()  # Iniciar a contagem do tempo","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:35.331721Z","iopub.execute_input":"2024-10-03T13:27:35.332082Z","iopub.status.idle":"2024-10-03T13:27:35.336455Z","shell.execute_reply.started":"2024-10-03T13:27:35.332048Z","shell.execute_reply":"2024-10-03T13:27:35.335468Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"%%time\nfor epoch in range(1, n_epochs + 1):\n    train()\n    val_loss = evaluate(model, val_data)\n    print('-' * 89)\n    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n        epoch, time.time() - start_time, val_loss, math.exp(val_loss)))\n    print('-' * 89)\n    scheduler.step()  # Atualizar a taxa de aprendizado","metadata":{"id":"nALirb_dtDCV","executionInfo":{"status":"error","timestamp":1726540919494,"user_tz":300,"elapsed":1149648,"user":{"displayName":"","userId":""}},"outputId":"4087d5db-4732-47d9-eea3-906fa73c1e8b","colab":{"base_uri":"https://localhost:8080/","height":460},"execution":{"iopub.status.busy":"2024-10-03T13:27:36.217434Z","iopub.execute_input":"2024-10-03T13:27:36.218078Z","iopub.status.idle":"2024-10-03T13:57:48.107977Z","shell.execute_reply.started":"2024-10-03T13:27:36.218042Z","shell.execute_reply":"2024-10-03T13:57:48.106951Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"| epoch   1 |   200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |   400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |   600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |   800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  1000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  1200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  1400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  1600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  1800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  2000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  2200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  2400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  2600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  2800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  3000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  3200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  3400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  3600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  3800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  4000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  4200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  4400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  4600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  4800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  5000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  5200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  5400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  5600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  5800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  6000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  6200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  6400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  6600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  6800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  7000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  7200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  7400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  7600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  7800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  8000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  8200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  8400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  8600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  8800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  9000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  9200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  9400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  9600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 |  9800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 10000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 10200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 10400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 10600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 10800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 11000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 11200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 11400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 11600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 11800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 12000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 12200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 12400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 12600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 12800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 13000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 13200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 13400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 13600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 13800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 14000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 14200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 14400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 14600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 14800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 15000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 15200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 15400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 15600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 15800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 16000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 16200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 16400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 16600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 16800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 17000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 17200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 17400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 17600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 17800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 18000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 18200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 18400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 18600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 18800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 19000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 19200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 19400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 19600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 19800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 20000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 20200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 20400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 20600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 20800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 21000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 21200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 21400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 21600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 21800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 22000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 22200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 22400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 22600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 22800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 23000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 23200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 23400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 23600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 23800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 24000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 24200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 24400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 24600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 24800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 25000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 25200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 25400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 25600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 25800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 26000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 26200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 26400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 26600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 26800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 27000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 27200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 27400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 27600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 27800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 28000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 28200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 28400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 28600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 28800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 29000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 29200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 29400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 29600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 29800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 30000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 30200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 30400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 30600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 30800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 31000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 31200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 31400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 31600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 31800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 32000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 32200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 32400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 32600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 32800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 33000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 33200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 33400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 33600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 33800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 34000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 34200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 34400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 34600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 34800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 35000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 35200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 35400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 35600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 35800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 36000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 36200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   1 | 36400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 363.56s | valid loss   nan | valid ppl      nan\n-----------------------------------------------------------------------------------------\n| epoch   2 |   200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |   400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |   600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |   800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  1000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  1200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  1400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  1600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  1800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  2000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  2200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  2400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  2600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  2800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  3000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  3200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  3400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  3600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  3800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  4000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  4200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  4400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  4600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  4800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  5000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  5200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  5400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  5600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  5800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  6000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  6200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  6400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  6600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  6800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  7000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  7200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  7400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  7600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  7800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  8000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  8200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  8400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  8600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  8800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  9000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  9200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  9400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  9600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 |  9800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 10000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 10200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 10400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 10600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 10800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 11000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 11200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 11400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 11600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 11800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 12000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 12200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 12400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 12600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 12800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 13000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 13200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 13400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 13600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 13800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 14000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 14200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 14400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 14600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 14800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 15000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 15200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 15400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 15600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 15800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 16000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 16200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 16400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 16600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 16800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 17000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 17200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 17400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 17600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 17800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 18000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 18200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 18400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 18600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 18800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 19000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 19200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 19400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 19600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 19800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 20000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 20200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 20400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 20600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 20800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 21000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 21200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 21400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 21600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 21800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 22000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 22200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 22400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 22600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 22800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 23000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 23200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 23400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 23600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 23800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 24000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 24200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 24400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 24600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 24800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 25000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 25200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 25400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 25600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 25800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 26000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 26200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 26400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 26600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 26800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 27000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 27200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 27400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 27600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 27800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 28000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 28200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 28400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 28600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 28800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 29000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 29200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 29400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 29600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 29800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 30000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 30200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 30400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 30600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 30800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 31000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 31200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 31400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 31600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 31800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 32000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 32200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 32400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 32600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 32800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 33000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 33200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 33400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 33600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 33800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 34000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 34200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 34400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 34600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 34800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 35000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 35200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 35400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 35600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 35800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 36000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 36200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   2 | 36400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n-----------------------------------------------------------------------------------------\n| end of epoch   2 | time: 726.35s | valid loss   nan | valid ppl      nan\n-----------------------------------------------------------------------------------------\n| epoch   3 |   200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |   400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |   600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |   800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  1000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  1200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  1400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  1600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  1800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  2000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  2200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  2400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  2600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  2800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  3000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  3200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  3400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  3600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  3800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  4000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  4200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  4400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  4600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  4800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  5000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  5200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  5400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  5600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  5800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  6000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  6200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  6400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  6600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  6800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  7000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  7200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  7400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  7600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  7800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  8000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  8200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  8400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  8600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  8800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  9000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  9200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  9400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  9600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 |  9800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 10000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 10200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 10400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 10600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 10800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 11000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 11200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 11400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 11600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 11800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 12000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 12200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 12400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 12600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 12800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 13000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 13200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 13400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 13600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 13800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 14000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 14200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 14400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 14600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 14800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 15000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 15200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 15400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 15600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 15800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 16000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 16200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 16400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 16600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 16800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 17000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 17200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 17400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 17600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 17800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 18000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 18200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 18400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 18600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 18800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 19000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 19200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 19400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 19600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 19800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 20000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 20200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 20400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 20600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 20800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 21000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 21200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 21400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 21600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 21800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 22000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 22200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 22400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 22600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 22800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 23000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 23200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 23400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 23600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 23800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 24000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 24200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 24400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 24600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 24800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 25000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 25200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 25400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 25600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 25800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 26000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 26200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 26400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 26600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 26800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 27000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 27200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 27400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 27600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 27800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 28000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 28200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 28400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 28600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 28800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 29000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 29200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 29400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 29600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 29800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 30000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 30200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 30400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 30600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 30800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 31000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 31200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 31400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 31600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 31800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 32000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 32200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 32400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 32600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 32800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 33000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 33200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 33400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 33600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 33800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 34000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 34200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 34400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 34600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 34800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 35000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 35200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 35400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 35600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 35800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 36000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 36200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   3 | 36400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n-----------------------------------------------------------------------------------------\n| end of epoch   3 | time: 1089.15s | valid loss   nan | valid ppl      nan\n-----------------------------------------------------------------------------------------\n| epoch   4 |   200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |   400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |   600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |   800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  1000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  1200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  1400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  1600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  1800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  2000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  2200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  2400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  2600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  2800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  3000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  3200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  3400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  3600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  3800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  4000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  4200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  4400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  4600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  4800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  5000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  5200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  5400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  5600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  5800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  6000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  6200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  6400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  6600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  6800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  7000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  7200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  7400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  7600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  7800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  8000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  8200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  8400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  8600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  8800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  9000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  9200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  9400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  9600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 |  9800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 10000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 10200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 10400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 10600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 10800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 11000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 11200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 11400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 11600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 11800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 12000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 12200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 12400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 12600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 12800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 13000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 13200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 13400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 13600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 13800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 14000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 14200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 14400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 14600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 14800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 15000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 15200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 15400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 15600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 15800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 16000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 16200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 16400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 16600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 16800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 17000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 17200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 17400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 17600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 17800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 18000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 18200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 18400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 18600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 18800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 19000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 19200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 19400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 19600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 19800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 20000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 20200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 20400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 20600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 20800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 21000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 21200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 21400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 21600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 21800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 22000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 22200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 22400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 22600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 22800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 23000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 23200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 23400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 23600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 23800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 24000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 24200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 24400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 24600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 24800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 25000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 25200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 25400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 25600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 25800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 26000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 26200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 26400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 26600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 26800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 27000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 27200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 27400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 27600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 27800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 28000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 28200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 28400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 28600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 28800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 29000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 29200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 29400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 29600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 29800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 30000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 30200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 30400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 30600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 30800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 31000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 31200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 31400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 31600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 31800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 32000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 32200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 32400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 32600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 32800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 33000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 33200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 33400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 33600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 33800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 34000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 34200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 34400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 34600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 34800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 35000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 35200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 35400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 35600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 35800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 36000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 36200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   4 | 36400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n-----------------------------------------------------------------------------------------\n| end of epoch   4 | time: 1451.22s | valid loss   nan | valid ppl      nan\n-----------------------------------------------------------------------------------------\n| epoch   5 |   200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |   400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |   600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |   800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  1000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  1200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  1400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  1600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  1800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  2000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  2200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  2400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  2600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  2800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  3000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  3200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  3400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  3600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  3800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  4000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  4200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  4400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  4600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  4800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  5000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  5200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  5400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  5600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  5800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  6000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  6200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  6400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  6600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  6800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  7000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  7200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  7400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  7600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  7800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  8000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  8200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  8400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  8600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  8800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  9000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  9200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  9400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  9600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 |  9800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 10000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 10200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 10400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 10600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 10800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 11000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 11200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 11400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 11600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 11800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 12000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 12200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 12400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 12600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 12800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 13000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 13200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 13400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 13600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 13800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 14000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 14200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 14400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 14600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 14800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 15000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 15200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 15400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 15600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 15800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 16000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 16200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 16400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 16600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 16800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 17000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 17200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 17400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 17600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 17800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 18000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 18200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 18400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 18600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 18800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 19000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 19200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 19400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 19600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 19800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 20000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 20200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 20400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 20600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 20800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 21000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 21200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 21400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 21600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 21800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 22000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 22200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 22400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 22600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 22800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 23000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 23200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 23400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 23600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 23800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 24000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 24200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 24400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 24600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 24800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 25000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 25200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 25400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 25600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 25800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 26000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 26200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 26400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 26600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 26800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 27000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 27200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 27400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 27600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 27800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 28000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 28200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 28400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 28600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 28800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 29000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 29200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 29400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 29600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 29800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 30000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 30200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 30400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 30600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 30800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 31000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 31200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 31400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 31600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 31800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 32000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 32200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 32400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 32600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 32800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 33000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 33200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 33400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 33600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 33800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 34000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 34200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 34400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 34600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 34800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 35000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 35200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 35400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 35600/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 35800/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 36000/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 36200/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n| epoch   5 | 36400/36490 batches | lr 5.00000 | loss   nan | ppl      nan\n-----------------------------------------------------------------------------------------\n| end of epoch   5 | time: 1812.77s | valid loss   nan | valid ppl      nan\n-----------------------------------------------------------------------------------------\nCPU times: user 29min 52s, sys: 8.2 s, total: 30min 1s\nWall time: 30min 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}